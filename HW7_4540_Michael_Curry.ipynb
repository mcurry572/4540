{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmi/tMwukbbm9/MiQ1zQsH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mcurry572/4540/blob/main/HW7_4540_Michael_Curry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The EEG dataset contains brain activity data recorded from different subjects. Each row represents a single EEG recording with multiple feature columns representing different EEG signal parameters. The final column represents the target variable. That can indicate a specific mental state, emotion, or classification category.\n",
        "\n",
        "# Inputs and Outputs:\n",
        "- **Inputs:** EEG signal features (numerical values representing brain activity)\n",
        "- **Output:** A categorical variable indicating a specific class or mental state\n",
        "\n",
        "# Classification or Regression problem?\n",
        "In this dataset, the target variable has a limited number of unique values, which makes this a classification problem."
      ],
      "metadata": {
        "id": "Oodo_6kHvhdf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hddTNGlMtjoL",
        "outputId": "6cd7ce7c-b5b6-4db9-9484-e8d94da5803b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12811 entries, 0 to 12810\n",
            "Data columns (total 15 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   SubjectID           12811 non-null  float64\n",
            " 1   VideoID             12811 non-null  float64\n",
            " 2   Attention           12811 non-null  float64\n",
            " 3   Mediation           12811 non-null  float64\n",
            " 4   Raw                 12811 non-null  float64\n",
            " 5   Delta               12811 non-null  float64\n",
            " 6   Theta               12811 non-null  float64\n",
            " 7   Alpha1              12811 non-null  float64\n",
            " 8   Alpha2              12811 non-null  float64\n",
            " 9   Beta1               12811 non-null  float64\n",
            " 10  Beta2               12811 non-null  float64\n",
            " 11  Gamma1              12811 non-null  float64\n",
            " 12  Gamma2              12811 non-null  float64\n",
            " 13  predefinedlabel     12811 non-null  float64\n",
            " 14  user-definedlabeln  12811 non-null  float64\n",
            "dtypes: float64(15)\n",
            "memory usage: 1.5 MB\n",
            "None\n",
            "\n",
            "First few rows:\n",
            "   SubjectID  VideoID  Attention  Mediation    Raw      Delta     Theta  \\\n",
            "0        0.0      0.0       56.0       43.0  278.0   301963.0   90612.0   \n",
            "1        0.0      0.0       40.0       35.0  -50.0    73787.0   28083.0   \n",
            "2        0.0      0.0       47.0       48.0  101.0   758353.0  383745.0   \n",
            "3        0.0      0.0       47.0       57.0   -5.0  2012240.0  129350.0   \n",
            "4        0.0      0.0       44.0       53.0   -8.0  1005145.0  354328.0   \n",
            "\n",
            "     Alpha1   Alpha2    Beta1     Beta2   Gamma1   Gamma2  predefinedlabel  \\\n",
            "0   33735.0  23991.0  27946.0   45097.0  33228.0   8293.0              0.0   \n",
            "1    1439.0   2240.0   2746.0    3687.0   5293.0   2740.0              0.0   \n",
            "2  201999.0  62107.0  36293.0  130536.0  57243.0  25354.0              0.0   \n",
            "3   61236.0  17084.0  11488.0   62462.0  49960.0  33932.0              0.0   \n",
            "4   37102.0  88881.0  45307.0   99603.0  44790.0  29749.0              0.0   \n",
            "\n",
            "   user-definedlabeln  \n",
            "0                 0.0  \n",
            "1                 0.0  \n",
            "2                 0.0  \n",
            "3                 0.0  \n",
            "4                 0.0  \n",
            "This is a binary classification problem.\n",
            "Logistic Regression Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.61      0.60      0.61      1298\n",
            "         1.0       0.60      0.60      0.60      1265\n",
            "\n",
            "    accuracy                           0.60      2563\n",
            "   macro avg       0.60      0.60      0.60      2563\n",
            "weighted avg       0.60      0.60      0.60      2563\n",
            "\n",
            "Epoch 1, Loss: 0.6216\n",
            "Epoch 2, Loss: 0.6860\n",
            "Epoch 3, Loss: 0.5420\n",
            "Epoch 4, Loss: 0.7118\n",
            "Epoch 5, Loss: 0.5994\n",
            "Epoch 6, Loss: 0.6618\n",
            "Epoch 7, Loss: 0.5998\n",
            "Epoch 8, Loss: 0.5286\n",
            "Epoch 9, Loss: 0.6710\n",
            "Epoch 10, Loss: 0.4329\n",
            "Neural Network Performance:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.62      0.64      1298\n",
            "           1       0.64      0.69      0.66      1265\n",
            "\n",
            "    accuracy                           0.65      2563\n",
            "   macro avg       0.66      0.65      0.65      2563\n",
            "weighted avg       0.66      0.65      0.65      2563\n",
            "\n",
            "Feature Engineering Completed.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define file path\n",
        "data_path = '/content/drive/My Drive/EEG_data.csv'\n",
        "\n",
        "# Load the EEG dataset\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Identify input features and target variable\n",
        "# Assuming the last column is the target (Adjust if necessary)\n",
        "X = df.iloc[:, :-1]\n",
        "y = df.iloc[:, -1]\n",
        "\n",
        "# Determine if it is a classification or regression problem\n",
        "if y.nunique() > 2:\n",
        "    print(\"This is a multi-class classification problem.\")\n",
        "elif y.nunique() == 2:\n",
        "    print(\"This is a binary classification problem.\")\n",
        "else:\n",
        "    print(\"This is a regression problem.\")\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = log_reg.predict(X_test_scaled)\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for PyTorch\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define Neural Network Model\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 16)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(16, 2)  # Assuming binary classification\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.softmax(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate and train the model\n",
        "input_size = X_train.shape[1]\n",
        "model = NeuralNet(input_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
        "\n",
        "# Evaluate the Neural Network Model\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "    print(\"Neural Network Performance:\")\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "\n",
        "evaluate_model(model, test_loader)\n",
        "\n",
        "# Feature Engineering\n",
        "# 1. Normalization is already done using StandardScaler\n",
        "# 2. Remove outliers using IQR method\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "df_cleaned = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# 3. Select a subset of features (assuming first 5 features for simplicity)\n",
        "df_selected = df_cleaned.iloc[:, :5]\n",
        "\n",
        "# 4. Select a subset of SubjectIDs (if applicable)\n",
        "if 'SubjectID' in df.columns:\n",
        "    df_subjects = df_cleaned[df_cleaned['SubjectID'].isin(df_cleaned['SubjectID'].unique()[:10])]\n",
        "else:\n",
        "    df_subjects = df_cleaned  # No SubjectID column found"
      ]
    }
  ]
}